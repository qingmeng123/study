# CPU Cache
缓存是位于CPU和内存之间的高速存储器，称为高速缓存，用于暂存从内存中读取的数据，以减少CPU访问内存的延迟。
缓存分为多级，L1 Cache、L2 Cache、L3 Cache等，由于速度逐级递减，但容量逐级递增。

## 1.为什么有了内存，还要CPU Cache
缓存的命中（数据已经在缓存中）能够大幅提高读取速度，用于缓解CPU与内存之间速度差异的问题。

## 2.CPU查询过程，CPU Cache和内存关系
- CPU Cache类似于设计应用程序的Redis层，没命中在去数据库访问数据，cpu则去访问内存
- CPU cache和内存采取映射方式：直接映射、组相联映射和全相联映射。
- - 在直接映射中，每个内存块只能映射到一个特定的缓存行。因此，每个缓存行中存储的数据来自于一个特定的内存块。
CPU Cache Line 存储的信息包括：缓存数据、缓存标签（标记哪个内存块）、一些控制位（如有效位、脏位等）。
组相联映射：

- - 在组相联映射中，每个内存块可以映射到一组缓存行中的一个。这意味着一组缓存行可能存储来自不同内存块的数据。
CPU Cache Line 存储的信息包括：缓存数据、缓存标签、组索引、一些控制位。
全相联映射：

- - 在全相联映射中，每个内存块可以映射到任意一个缓存行。这意味着任何缓存行都可能存储来自不同内存块的数据。
CPU Cache Line 存储的信息包括：缓存数据、缓存标签、一些控制位。
- 一个内存的访问地址，包括组标记、CPU Cache Line 索引、偏移量这三种信息。偏移量用于在对应的 CPU Cache Line 中数据块中找到所需的字（cpu所需要的CPU Cache Line 中一个数据片段）

## 3.提高缓存命中率
- L1 index0数据缓存:按照内存布局顺序访问,CPU Cache 一次性能加载数据的大小，Linux 里通过 coherency_line_size 配置查看，通常是 64 个字节。
- L1 index1指令缓存:CPU有分支预测器，如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快。
- 多核 CPU 的缓存命中率：可以把线程绑定在某一个 CPU 核心上，go标准库syscall有相关的